{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plZd6ecZATgE",
        "outputId": "b57bbe1c-f0ad-4f6f-b560-0bf7a5f4fa71"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Swe39Yfe5qyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e340f58-f265-4525-e5f2-0305a5d23e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recipe Title: Ø´ÙˆØ±Ø¨Ø© Ø§Ù„ØªÙ„ÙŠØªÙ„ÙŠ Ø¨Ø§Ù„Ø¯Ø¬Ø§Ø¬ ğŸ—Ø§Ù„Ø³Ø±ÙŠØ¹Ø© ÙˆØ§Ù„Ø£Ù‡Ù… Ù„Ø°ÙŠØ°Ø© Ø¬Ø¯Ø§ ğŸ˜‹\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24316735-%D8%B4%D9%88%D8%B1%D8%A8%D8%A9-%D8%A7%D9%84%D8%AA%D9%84%D9%8A%D8%AA%D9%84%D9%8A-%D8%A8%D8%A7%D9%84%D8%AF%D8%AC%D8%A7%D8%AC-%D8%A7%D9%84%D8%B3%D8%B1%D9%8A%D8%B9%D8%A9-%D9%88%D8%A7%D9%84%D8%A3%D9%87%D9%85-%D9%84%D8%B0%D9%8A%D8%B0%D8%A9-%D8%AC%D8%AF%D8%A7\n",
            "==================================================\n",
            "Recipe Title: Ø­Ù…ÙŠØ³\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24315573-%D8%AD%D9%85%D9%8A%D8%B3\n",
            "==================================================\n",
            "Recipe Title: ØªÙ…Ø± Ù…Ø­Ø´ÙŠ ÙˆÙ…ØºÙ„Ù Ø¨Ø§Ù„Ø´ÙƒÙˆÙ„Ø© Ù„Ù„Ù…Ù†Ø§Ø³Ø¨Ø§Øª\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24237630-%D8%AA%D9%85%D8%B1-%D9%85%D8%AD%D8%B4%D9%8A-%D9%88%D9%85%D8%BA%D9%84%D9%81-%D8%A8%D8%A7%D9%84%D8%B4%D9%83%D9%88%D9%84%D8%A9-%D9%84%D9%84%D9%85%D9%86%D8%A7%D8%B3%D8%A8%D8%A7%D8%AA\n",
            "==================================================\n",
            "Recipe Title: Ø¨Ø·Ø§Ø·Ø§ ÙƒÙˆØ´Ø©\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24264997-%D8%A8%D8%B7%D8%A7%D8%B7%D8%A7-%D9%83%D9%88%D8%B4%D8%A9\n",
            "==================================================\n",
            "Recipe Title: ØºØ±Ø§ØªØ§Ù† Ø¨Ø§Ù„Ø®Ø¶Ø± Ù…Ø¨Ø´ÙˆØ±Ø©\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24315139-%D8%BA%D8%B1%D8%A7%D8%AA%D8%A7%D9%86-%D8%A8%D8%A7%D9%84%D8%AE%D8%B6%D8%B1-%D9%85%D8%A8%D8%B4%D9%88%D8%B1%D8%A9\n",
            "==================================================\n",
            "Recipe Title: ÙƒØ³ÙƒØ³\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24313329-%D9%83%D8%B3%D9%83%D8%B3\n",
            "==================================================\n",
            "Recipe Title: Ø§Ù„Ø±ÙÙŠØ³ Ø§Ù„Ù‚Ø³Ù†Ø·ÙŠÙ†ÙŠ\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24313185-%D8%A7%D9%84%D8%B1%D9%81%D9%8A%D8%B3-%D8%A7%D9%84%D9%82%D8%B3%D9%86%D8%B7%D9%8A%D9%86%D9%8A\n",
            "==================================================\n",
            "Recipe Title: ØªÙˆÙ†Ø© Ù…Ø´Ø±Ù…Ù„Ø©ğŸ§¡\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24312679-%D8%AA%D9%88%D9%86%D8%A9-%D9%85%D8%B4%D8%B1%D9%85%D9%84%D8%A9\n",
            "==================================================\n",
            "Recipe Title: Ø£Ø³Ù‡Ù„ Ø·Ø±ÙŠÙ‚Ø© Ù‚Ø±Ø§ØªØ§Ù† Ø¨Ø·Ø§Ø·Ø§ Ù…Ù‚Ù„ÙŠØ© Ù…Ø¹ ØµÙ„ØµØ© Ø§Ù„Ø·Ù…Ø§Ø·Ù… ÙˆØ¨ÙŠØ¶ ÙˆØ¬Ø¨Ù† Ø·Ø±ÙŠ ğŸ¥”ğŸ…ğŸ¥šğŸ§€\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24311634-%D8%A3%D8%B3%D9%87%D9%84-%D8%B7%D8%B1%D9%8A%D9%82%D8%A9-%D9%82%D8%B1%D8%A7%D8%AA%D8%A7%D9%86-%D8%A8%D8%B7%D8%A7%D8%B7%D8%A7-%D9%85%D9%82%D9%84%D9%8A%D8%A9-%D9%85%D8%B9-%D8%B5%D9%84%D8%B5%D8%A9-%D8%A7%D9%84%D8%B7%D9%85%D8%A7%D8%B7%D9%85-%D9%88%D8%A8%D9%8A%D8%B6-%D9%88%D8%AC%D8%A8%D9%86-%D8%B7%D8%B1%D9%8A\n",
            "==================================================\n",
            "Recipe Title: ÙƒØ³ÙƒØ³ÙŠ Ø§Ù„Ø´Ø¹ÙŠØ±\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24310359-%D9%83%D8%B3%D9%83%D8%B3%D9%8A-%D8%A7%D9%84%D8%B4%D8%B9%D9%8A%D8%B1\n",
            "==================================================\n",
            "Recipe Title: Ù…Ø¹Ù‚ÙˆØ¯Ø© Ø¥Ù‚ØªØµØ§Ø¯ÙŠØ© ğŸ˜‹\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24307845-%D9%85%D8%B9%D9%82%D9%88%D8%AF%D8%A9-%D8%A5%D9%82%D8%AA%D8%B5%D8%A7%D8%AF%D9%8A%D8%A9\n",
            "==================================================\n",
            "Recipe Title: ÙƒØ³ÙƒØ³ Ø¨Ù…Ø±Ù‚ Ø£Ø­Ù…Ø±\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24307707-%D9%83%D8%B3%D9%83%D8%B3-%D8%A8%D9%85%D8%B1%D9%82-%D8%A3%D8%AD%D9%85%D8%B1\n",
            "==================================================\n",
            "Recipe Title: ÙƒØ³ÙƒØ³ Ø¨Ø§Ù„Ù„Ø­Ù… ÙˆØ§Ù„Ø­Ù…Øµ ÙˆØ§Ù„Ø®Ø¶Ø±\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24307537-%D9%83%D8%B3%D9%83%D8%B3-%D8%A8%D8%A7%D9%84%D9%84%D8%AD%D9%85-%D9%88%D8%A7%D9%84%D8%AD%D9%85%D8%B5-%D9%88%D8%A7%D9%84%D8%AE%D8%B6%D8%B1\n",
            "==================================================\n",
            "Recipe Title: ÙƒØ³ÙƒØ³ Ù‚Ù…Ø­ ÙƒØ§Ù…Ù„ ÙˆÙ…Ø±Ù‚Ø© Ø­Ù…Ø±Ø§Ø¡ ÙˆØ¯Ø¬Ø§Ø¬\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24307535-%D9%83%D8%B3%D9%83%D8%B3-%D9%82%D9%85%D8%AD-%D9%83%D8%A7%D9%85%D9%84-%D9%88%D9%85%D8%B1%D9%82%D8%A9-%D8%AD%D9%85%D8%B1%D8%A7%D8%A1-%D9%88%D8%AF%D8%AC%D8%A7%D8%AC\n",
            "==================================================\n",
            "Recipe Title: ÙƒØ³ÙƒØ³ Ù…Ø±Ù‚ Ø§Ø¨ÙŠØ¶ Ø¨Ø§Ù„Ø­Ù…Ø©ğŸ¤¤ğŸ˜\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24074366-%D9%83%D8%B3%D9%83%D8%B3-%D9%85%D8%B1%D9%82-%D8%A7%D8%A8%D9%8A%D8%B6-%D8%A8%D8%A7%D9%84%D8%AD%D9%85%D8%A9\n",
            "==================================================\n",
            "Recipe Title: Ø§Ù„Ù…Ù‚ÙÙˆÙ„ ÙƒØ³ÙƒØ³ Ø¨Ø®Ø¶Ø§Ø± ÙˆØ²ÙŠØª Ø²ÙŠØªÙˆÙ†\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24106670-%D8%A7%D9%84%D9%85%D9%82%D9%81%D9%88%D9%84-%D9%83%D8%B3%D9%83%D8%B3-%D8%A8%D8%AE%D8%B6%D8%A7%D8%B1-%D9%88%D8%B2%D9%8A%D8%AA-%D8%B2%D9%8A%D8%AA%D9%88%D9%86\n",
            "==================================================\n",
            "Recipe Title: Ø­Ù…ÙŠØ³ Ø­Ø§Ø± ğŸŒ¶\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24275712-%D8%AD%D9%85%D9%8A%D8%B3-%D8%AD%D8%A7%D8%B1\n",
            "==================================================\n",
            "Recipe Title: Ø´Ø·ÙŠØ·Ø­Ø© Ø²ÙŠØªÙˆÙ† Ø¨Ø§Ù„Ø®Ø±Ø´Ù ÙˆØ§Ù„Ø¬Ø²Ø± Ù…Ø±Ù‚Ø© Ø¨ÙŠØ¶Ø§Ø¡\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24303525-%D8%B4%D8%B7%D9%8A%D8%B7%D8%AD%D8%A9-%D8%B2%D9%8A%D8%AA%D9%88%D9%86-%D8%A8%D8%A7%D9%84%D8%AE%D8%B1%D8%B4%D9%81-%D9%88%D8%A7%D9%84%D8%AC%D8%B2%D8%B1-%D9%85%D8%B1%D9%82%D8%A9-%D8%A8%D9%8A%D8%B6%D8%A7%D8%A1\n",
            "==================================================\n",
            "Recipe Title: Ù…Ø¹ÙƒØ±ÙˆÙ†Ø© Ø¨Ø§Ù„Ù…Ø±Ù‚ âœ¨\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24302772-%D9%85%D8%B9%D9%83%D8%B1%D9%88%D9%86%D8%A9-%D8%A8%D8%A7%D9%84%D9%85%D8%B1%D9%82\n",
            "==================================================\n",
            "Recipe Title: ÙƒØ³ÙƒØ³ Ø¨Ø§Ù„ÙÙˆÙ„ Ø§Ù„Ø§Ø®Ø¶Ø± Ù…Ø¹ Ø§Ù„Ø±Ø§ÙŠØ¨ğŸ¼ ğŸ¤ğŸŒ»ğŸ’ğŸ‘\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24301014-%D9%83%D8%B3%D9%83%D8%B3-%D8%A8%D8%A7%D9%84%D9%81%D9%88%D9%84-%D8%A7%D9%84%D8%A7%D8%AE%D8%B6%D8%B1-%D9%85%D8%B9-%D8%A7%D9%84%D8%B1%D8%A7%D9%8A%D8%A8\n",
            "==================================================\n",
            "Recipe Title: Ù…Ø³Ù…Ù†\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24300481-%D9%85%D8%B3%D9%85%D9%86\n",
            "==================================================\n",
            "Recipe Title: ÙƒØ±Ø§Ù†ØªÙŠÙƒØ§ Ù„Ø´Ø®Øµ ÙˆØ§Ø­Ø¯\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24300647-%D9%83%D8%B1%D8%A7%D9%86%D8%AA%D9%8A%D9%83%D8%A7-%D9%84%D8%B4%D8%AE%D8%B5-%D9%88%D8%A7%D8%AD%D8%AF\n",
            "==================================================\n",
            "Recipe Title: ÙƒØ³ÙƒØ³ Ø§Ù„Ø´Ø¹ÙŠØ± Ø¨Ø§Ù„Ù„Ø­Ù… ÙˆØ§Ù„Ø®Ø¶Ø±\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24300284-%D9%83%D8%B3%D9%83%D8%B3-%D8%A7%D9%84%D8%B4%D8%B9%D9%8A%D8%B1-%D8%A8%D8%A7%D9%84%D9%84%D8%AD%D9%85-%D9%88%D8%A7%D9%84%D8%AE%D8%B6%D8%B1\n",
            "==================================================\n",
            "Recipe Title: ÙƒÙŠÙÙŠØ© Ø§Ø¹Ø¯Ø§Ø¯ (Ø·Ù‡ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø®Ø§Ø±) ÙƒØ³ÙƒØ³ Ø§Ù„Ø´Ø¹ÙŠØ±\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24300220-%D9%83%D9%8A%D9%81%D9%8A%D8%A9-%D8%A7%D8%B9%D8%AF%D8%A7%D8%AF-%D8%B7%D9%87%D9%8A-%D8%B9%D9%84%D9%89-%D8%A7%D9%84%D8%A8%D8%AE%D8%A7%D8%B1-%D9%83%D8%B3%D9%83%D8%B3-%D8%A7%D9%84%D8%B4%D8%B9%D9%8A%D8%B1\n",
            "==================================================\n",
            "Recipe Title: ØºØ±Ø§ØªØ§Ù† Ø§Ù„Ø¨Ø·Ø§Ø·Ø³ Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24299551-%D8%BA%D8%B1%D8%A7%D8%AA%D8%A7%D9%86-%D8%A7%D9%84%D8%A8%D8%B7%D8%A7%D8%B7%D8%B3-%D8%A7%D9%84%D9%81%D8%B1%D9%86%D8%B3%D9%8A%D8%A9\n",
            "==================================================\n",
            "Recipe Title: ÙƒØ³ÙƒØ³ Ø¨Ù…Ø±Ù‚ Ø§Ù„ÙÙˆÙ„ Ø§Ù„ÙŠØ§Ø¨Ø³\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24298074-%D9%83%D8%B3%D9%83%D8%B3-%D8%A8%D9%85%D8%B1%D9%82-%D8%A7%D9%84%D9%81%D9%88%D9%84-%D8%A7%D9%84%D9%8A%D8%A7%D8%A8%D8%B3\n",
            "==================================================\n",
            "Recipe Title: ØºØ±Ø§ØªØ§Ù† Ø¨Ø§Ù„ØªÙˆÙ†Ø© Ø¥Ù‚ØªØµØ§Ø¯ÙŠØ© ÙˆØ³Ù‡Ù„Ø©\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24249302-%D8%BA%D8%B1%D8%A7%D8%AA%D8%A7%D9%86-%D8%A8%D8%A7%D9%84%D8%AA%D9%88%D9%86%D8%A9-%D8%A5%D9%82%D8%AA%D8%B5%D8%A7%D8%AF%D9%8A%D8%A9-%D9%88%D8%B3%D9%87%D9%84%D8%A9\n",
            "==================================================\n",
            "Recipe Title: ÙƒØ³ÙƒØ³ Ø¨Ø§Ù„Ø¯Ø¬Ø§Ø¬â¤ï¸\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24297276-%D9%83%D8%B3%D9%83%D8%B3-%D8%A8%D8%A7%D9%84%D8%AF%D8%AC%D8%A7%D8%AC\n",
            "==================================================\n",
            "Recipe Title: Ø¯ÙˆÙ„Ù…Ø© Ø§Ù„Ù‚Ø±Ù†ÙˆÙ† Ø·Ø¨Ù‚ Ø¬Ø²Ø§Ø¦Ø±ÙŠ\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24296206-%D8%AF%D9%88%D9%84%D9%85%D8%A9-%D8%A7%D9%84%D9%82%D8%B1%D9%86%D9%88%D9%86-%D8%B7%D8%A8%D9%82-%D8%AC%D8%B2%D8%A7%D8%A6%D8%B1%D9%8A\n",
            "==================================================\n",
            "Recipe Title: Ø´ÙƒØ´ÙˆÙƒØ© Ø¨Ø·Ø§Ø·Ø§ Ø¨Ø§Ù„Ø¨ÙŠØ¶ ÙˆØ§Ù„ÙÙ„ÙÙ„ ÙˆØ§Ù„Ø¬Ø¨Ù†\n",
            "Recipe URL: https://cookpad.com/dz/%D9%88%D8%B5%D9%81%D8%A7%D8%AA/24296074-%D8%B4%D9%83%D8%B4%D9%88%D9%83%D8%A9-%D8%A8%D8%B7%D8%A7%D8%B7%D8%A7-%D8%A8%D8%A7%D9%84%D8%A8%D9%8A%D8%B6-%D9%88%D8%A7%D9%84%D9%81%D9%84%D9%81%D9%84-%D9%88%D8%A7%D9%84%D8%AC%D8%A8%D9%86\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL of the Cookpad page for Algerian recipes\n",
        "url = 'https://cookpad.com/dz/search/%D9%88%D8%B5%D9%81%D8%A7%D8%AA%20%D9%88%D8%A7%D9%83%D9%84%D8%A7%D8%AA%20%D8%AC%D8%B2%D8%A7%D8%A6%D8%B1%D9%8A%D8%A9'\n",
        "\n",
        "# Send HTTP GET request to the page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the page content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all <a> tags with the relevant class (block-link__main)\n",
        "    links = soup.find_all('a', class_='block-link__main')  # This class is from your provided HTML snippet\n",
        "\n",
        "    # Iterate through all the found <a> tags and print their content and href attribute\n",
        "    for link in links:\n",
        "        # Get the href attribute (URL of the recipe)\n",
        "        href = link.get('href')\n",
        "\n",
        "        # Get the text content inside the <a> tag (title of the recipe)\n",
        "        text = link.get_text(strip=True)\n",
        "\n",
        "        # Print the result\n",
        "        print(f\"Recipe Title: {text}\")\n",
        "        print(f\"Recipe URL: https://cookpad.com{href}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "else:\n",
        "    print(\"Failed to retrieve the page.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "second\n",
        "\n"
      ],
      "metadata": {
        "id": "t0yVydaRIW4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "!pip install requests\n",
        "\n",
        "# URL of the Cookpad page for Algerian recipes\n",
        "url = 'https://cookpad.com/dz/search/%D9%88%D8%B5%D9%81%D8%A7%D8%AA%20%D9%88%D8%A7%D9%83%D9%84%D8%A7%D8%AA%20%D8%AC%D8%B2%D8%A7%D8%A6%D8%B1%D9%8A%D8%A9'\n",
        "\n",
        "# Send HTTP GET request to the page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the page content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all <a> tags with the relevant class (block-link__main)\n",
        "    links = soup.find_all('a', class_='block-link__main')  # This class is from your provided HTML snippet\n",
        "\n",
        "    # Iterate through all the found <a> tags and print their content and href attribute\n",
        "    for link in links:\n",
        "        # Get the href attribute (URL of the recipe)\n",
        "        href = link.get('href')\n",
        "\n",
        "        # Construct the full recipe URL\n",
        "        recipe_url = f\"https://cookpad.com{href}\"\n",
        "\n",
        "        try:\n",
        "          # Send a request to the recipe page\n",
        "          recipe_response = requests.get(recipe_url)\n",
        "          recipe_response.raise_for_status() # Raise an exception for bad status codes\n",
        "\n",
        "          # Parse the recipe page\n",
        "          recipe_soup = BeautifulSoup(recipe_response.text, 'html.parser')\n",
        "\n",
        "          # Find the ingredient list\n",
        "          ingredient_list = recipe_soup.find('div', class_='ingredient-list lg:overflow-y-auto')\n",
        "\n",
        "          if ingredient_list:\n",
        "              # Extract ingredients\n",
        "              ingredients = [li.get_text(strip=True) for li in ingredient_list.find_all('li')]\n",
        "              print(f\"Recipe URL: {recipe_url}\")\n",
        "              print(\"Ingredients:\")\n",
        "              for ingredient in ingredients:\n",
        "                  print(ingredient)\n",
        "              print(\"=\"*50)\n",
        "          else:\n",
        "              print(f\"Could not find ingredient list for: {recipe_url}\")\n",
        "              print(\"=\" * 50)\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "          print(f\"Error fetching or parsing {recipe_url}: {e}\")\n",
        "          print(\"=\"*50)\n",
        "\n",
        "else:\n",
        "    print(\"Failed to retrieve the main page.\")"
      ],
      "metadata": {
        "id": "1DGGcYDrEZrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "!pip install requests\n",
        "\n",
        "# URL of the Cookpad page for Algerian recipes\n",
        "url = 'https://cookpad.com/dz/search/%D9%88%D8%B5%D9%81%D8%A7%D8%AA%20%D9%88%D8%A7%D9%83%D9%84%D8%A7%D8%AA%20%D8%AC%D8%B2%D8%A7%D8%A6%D8%B1%D9%8A%D8%A9'\n",
        "\n",
        "# Send HTTP GET request to the page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the page content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all <a> tags with the relevant class (block-link__main)\n",
        "    links = soup.find_all('a', class_='block-link__main')  # This class is from your provided HTML snippet\n",
        "\n",
        "    # Iterate through all the found <a> tags and print their content and href attribute\n",
        "    for link in links:\n",
        "        # Get the href attribute (URL of the recipe)\n",
        "        href = link.get('href')\n",
        "\n",
        "        # Construct the full recipe URL\n",
        "        recipe_url = f\"https://cookpad.com{href}\"\n",
        "\n",
        "        try:\n",
        "          # Send a request to the recipe page\n",
        "          recipe_response = requests.get(recipe_url)\n",
        "          recipe_response.raise_for_status() # Raise an exception for bad status codes\n",
        "\n",
        "          # Parse the recipe page\n",
        "          recipe_soup = BeautifulSoup(recipe_response.text, 'html.parser')\n",
        "\n",
        "          # Find the recipe title\n",
        "          recipe_title_element = recipe_soup.find('h1', class_='break-words')\n",
        "          recipe_title = recipe_title_element.get_text(strip=True) if recipe_title_element else \"Recipe Title Not Found\"\n",
        "\n",
        "          # Find the ingredient list\n",
        "          ingredient_list = recipe_soup.find('div', class_='ingredient-list lg:overflow-y-auto')\n",
        "\n",
        "          if ingredient_list:\n",
        "              # Extract ingredients\n",
        "              ingredients = [li.get_text(strip=True) for li in ingredient_list.find_all('li')]\n",
        "              print(f\"Recipe Title: {recipe_title}\") # Print the recipe title\n",
        "              print(f\"Recipe URL: {recipe_url}\")\n",
        "              print(\"Ingredients:\")\n",
        "              for ingredient in ingredients:\n",
        "                  print(ingredient)\n",
        "              print(\"=\"*50)\n",
        "          else:\n",
        "              print(f\"Could not find ingredient list for: {recipe_url}\")\n",
        "              print(\"=\" * 50)\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "          print(f\"Error fetching or parsing {recipe_url}: {e}\")\n",
        "          print(\"=\"*50)\n",
        "\n",
        "else:\n",
        "    print(\"Failed to retrieve the main page.\")"
      ],
      "metadata": {
        "id": "PrkivoeYEevV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# URL of the Cookpad page for Algerian recipes\n",
        "url = 'https://cookpad.com/dz/search/%D9%88%D8%B5%D9%81%D8%A7%D8%AA%20%D9%88%D8%A7%D9%83%D9%84%D8%A7%D8%AA%20%D8%AC%D8%B2%D8%A7%D8%A6%D8%B1%D9%8A%D8%A9'\n",
        "\n",
        "# Send HTTP GET request to the page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the page content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all <a> tags with the relevant class (block-link__main)\n",
        "    links = soup.find_all('a', class_='block-link__main')\n",
        "\n",
        "    # List to store recipe data\n",
        "    recipes = []\n",
        "\n",
        "    # Iterate through all the found <a> tags\n",
        "    for link in links:\n",
        "        # Get the href attribute (URL of the recipe)\n",
        "        href = link.get('href')\n",
        "\n",
        "        # Construct the full recipe URL\n",
        "        recipe_url = f\"https://cookpad.com{href}\"\n",
        "\n",
        "        try:\n",
        "            # Send a request to the recipe page\n",
        "            recipe_response = requests.get(recipe_url)\n",
        "            recipe_response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "            # Parse the recipe page\n",
        "            recipe_soup = BeautifulSoup(recipe_response.text, 'html.parser')\n",
        "\n",
        "            # Find the recipe title\n",
        "            recipe_title_element = recipe_soup.find('h1', class_='break-words')\n",
        "            recipe_title = recipe_title_element.get_text(strip=True) if recipe_title_element else \"Recipe Title Not Found\"\n",
        "\n",
        "            # Find the ingredient list\n",
        "            ingredient_list = recipe_soup.find('div', class_='ingredient-list lg:overflow-y-auto')\n",
        "\n",
        "            if ingredient_list:\n",
        "                # Extract ingredients\n",
        "                ingredients = [li.get_text(strip=True) for li in ingredient_list.find_all('li')]\n",
        "                recipes.append({'Dish Name': recipe_title, 'Ingredients': ingredients})\n",
        "            else:\n",
        "                print(f\"Could not find ingredient list for: {recipe_url}\")\n",
        "                print(\"=\" * 50)\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching or parsing {recipe_url}: {e}\")\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "    # Write the scraped data to a CSV file\n",
        "    with open('recipes.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['Dish Name', 'Ingredients']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for recipe in recipes:\n",
        "            writer.writerow({'Dish Name': recipe['Dish Name'],\n",
        "                             'Ingredients': ', '.join(recipe['Ingredients'])})  # Join ingredients into a single string\n",
        "\n",
        "    print(\"Scraping complete! Data saved to recipes.csv\")\n",
        "\n",
        "else:\n",
        "    print(\"Failed to retrieve the main page.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSKD1h2qC5-5",
        "outputId": "0799ad59-cbb8-4762-b4fe-1f3fa643e3de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping complete! Data saved to recipes.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: scrap from this page https://www.chefspencil.com/top-25-most-popular-foods-in-algeria/  the title from the elements <h2 class=\"wp-block-heading\">2. Baklawa (Baklava)&nbsp;</h2> and the url of recipe <a class=\"wp-block-button__link has-vivid-red-background-color has-background wp-element-button\" href=\"https://www.myexcellentdegustations.com/algerian-thin-flatbread-with-meat-sauce-chakhchoukha/\" style=\"border-radius:0px\" target=\"_blank\" rel=\"noreferrer noopener\">View Recipe</a>\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL of the Chefspencil page\n",
        "url = 'https://www.chefspencil.com/top-25-most-popular-foods-in-algeria/'\n",
        "\n",
        "# Send HTTP GET request to the page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the page content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all <h2> tags with the class 'wp-block-heading'\n",
        "    titles = soup.find_all('h2', class_='wp-block-heading')\n",
        "\n",
        "    # Find all <a> tags with the specified class and attributes\n",
        "    recipe_links = soup.find_all(\n",
        "        'a',\n",
        "        class_='wp-block-button__link has-vivid-red-background-color has-background wp-element-button',\n",
        "        href=True  # Ensure the <a> tag has an href attribute\n",
        "    )\n",
        "\n",
        "    # Iterate through titles and recipe_links and print them\n",
        "    for title, link in zip(titles, recipe_links):\n",
        "        print(f\"Title: {title.text.strip()}\")  # Extract and clean up title text\n",
        "        print(f\"Recipe URL: {link['href']}\")\n",
        "        print(\"=\"*50)\n",
        "else:\n",
        "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Na3R8SHImYP",
        "outputId": "8e9db14b-c88c-48cf-fb9e-9e61a85cd444"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: 1. Chekhchoukha\n",
            "Recipe URL: https://www.myexcellentdegustations.com/algerian-thin-flatbread-with-meat-sauce-chakhchoukha/\n",
            "==================================================\n",
            "Title: 2. Baklawa (Baklava)\n",
            "Recipe URL: https://www.chefspencil.com/turkish-baklava/\n",
            "==================================================\n",
            "Title: 3. Couscous\n",
            "Recipe URL: https://www.chefspencil.com/turkish-chicken-wings-with-vegetables-couscous/\n",
            "==================================================\n",
            "Title: 4. Zviti\n",
            "Recipe URL: https://www.myexcellentdegustations.com/%F0%9F%87%A9%F0%9F%87%BF-algerian-spicy-dish-from-bousaada-region-called-zviti/\n",
            "==================================================\n",
            "Title: 5. Dobara\n",
            "Recipe URL: https://keeshaskitchen.com/algerian-doubara/\n",
            "==================================================\n",
            "Title: 6. Usban\n",
            "Recipe URL: https://afrifoodnetwork.com/recipes/main-course-recipes/usban/\n",
            "==================================================\n",
            "Title: 7. Zlabia\n",
            "Recipe URL: https://afrifoodnetwork.com/recipes/dessert-recipes/zlabia/\n",
            "==================================================\n",
            "Title: 8. Mhajab\n",
            "Recipe URL: https://www.mycookingjourney.com/mahjouba-algerian-crepes/\n",
            "==================================================\n",
            "Title: 9. Al-Shetitha\n",
            "Recipe URL: https://www.thefooddictator.com/hirshon-algerian-berkoukes-soup-%D8%A8%D8%B1%D9%83%D9%88%D9%83%D8%B3/\n",
            "==================================================\n",
            "Title: 10. Berkoukes\n",
            "Recipe URL: https://www.myexcellentdegustations.com/%F0%9F%87%A9%F0%9F%87%BF-algerian-homemade-rechta-noodles/\n",
            "==================================================\n",
            "Title: 11.Â Rachta\n",
            "Recipe URL: https://www.notesfromamessykitchen.com/recipe/algerian-makroud/\n",
            "==================================================\n",
            "Title: 12.Â Makroud\n",
            "Recipe URL: https://www.punchfork.com/recipe/Samsa-Algerian-Almond-Orange-Triangle-Cookies-Food52\n",
            "==================================================\n",
            "Title: 13. Almonds Triangles\n",
            "Recipe URL: https://arabicfoodtips.com/egyptian-zainab-fingers-recipe-sawabe-zainab/\n",
            "==================================================\n",
            "Title: 14. Swabaa Zainab\n",
            "Recipe URL: http://couscousandpudding.over-blog.com/article-algerian-sweets-el-djouza-or-walnut-69233998.html\n",
            "==================================================\n",
            "Title: 15. Djouzia\n",
            "Recipe URL: https://thetealtadjine.blogspot.com/2010/08/chourba-frik-algerian-green-wheat-soup.html\n",
            "==================================================\n",
            "Title: 16. El-Jari (Chorba)\n",
            "Recipe URL: https://tastymediterranean.com/recipe/how-to-prepare-authentic-algerian-tamina/\n",
            "==================================================\n",
            "Title: 17. Tamina\n",
            "Recipe URL: https://butfirstchai.com/mesfouf-steamed-sweet-couscous/\n",
            "==================================================\n",
            "Title: 18. Mesfouf\n",
            "Recipe URL: https://www.gourmandize.com/recipe-48294-tcharek-m-seker-algerian-sweets.htm\n",
            "==================================================\n",
            "Title: 19. Tcharek\n",
            "Recipe URL: https://cooking-ez.com/divers/recipe-algerian-brik-rolls.php\n",
            "==================================================\n",
            "Title: 20.Â El- Makhtouma\n",
            "Recipe URL: https://www.chefspencil.com/lamb-shank-tagine/\n",
            "==================================================\n",
            "Title: 21.Â Brik (Bourak)\n",
            "Recipe URL: https://petitepaniere.com/2020/04/26/mtewem-marqa-hamra-algerian-garlicky-meat-balls-in-red-sauce/\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def scrape_recipe(url):\n",
        "    \"\"\"Scrapes the recipe title and ingredients from a given URL.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract the recipe title\n",
        "        title_element = soup.find('h1', class_='break-words') # Use the correct class for the title\n",
        "        title = title_element.text.strip() if title_element else \"Recipe Title Not Found\"\n",
        "\n",
        "        # Extract the ingredients\n",
        "        ingredients = []\n",
        "        ingredient_list = soup.find('div', class_='ingredient-list lg:overflow-y-auto')\n",
        "        if ingredient_list:\n",
        "          ingredients = [li.get_text(strip=True) for li in ingredient_list.find_all('li')]\n",
        "\n",
        "        return {'Dish Name': title, 'Ingredients': ingredients}\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching or parsing {url}: {e}\")\n",
        "        return None\n",
        "    except AttributeError as e:\n",
        "        print(f\"Error parsing HTML for {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# URL of the Chefspencil page\n",
        "url = 'https://www.chefspencil.com/top-25-most-popular-foods-in-algeria/'\n",
        "\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    recipes = []\n",
        "    # Find all recipe links on the page\n",
        "    recipe_links = soup.find_all('a', class_='wp-block-button__link')\n",
        "    for link in recipe_links:\n",
        "        recipe_url = link['href']\n",
        "        recipe_data = scrape_recipe(recipe_url)\n",
        "        if recipe_data:\n",
        "            recipes.append(recipe_data)\n",
        "\n",
        "    # Write the scraped data to a CSV file\n",
        "    with open('algerian_recipes.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['Dish Name', 'Ingredients']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for recipe in recipes:\n",
        "            writer.writerow({'Dish Name': recipe['Dish Name'],\n",
        "                             'Ingredients': ', '.join(recipe['Ingredients'])})\n",
        "\n",
        "    print(\"Scraping complete! Data saved to algerian_recipes.csv\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching or parsing {url}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI1VPRLcJKw-",
        "outputId": "cd9e661c-7b37-4601-de8d-6812cf339ff4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching or parsing https://www.myexcellentdegustations.com/algerian-thin-flatbread-with-meat-sauce-chakhchoukha/: 406 Client Error: Not Acceptable for url: https://www.myexcellentdegustations.com/algerian-thin-flatbread-with-meat-sauce-chakhchoukha/\n",
            "Error fetching or parsing https://www.myexcellentdegustations.com/%F0%9F%87%A9%F0%9F%87%BF-algerian-spicy-dish-from-bousaada-region-called-zviti/: 406 Client Error: Not Acceptable for url: https://www.myexcellentdegustations.com/%F0%9F%87%A9%F0%9F%87%BF-algerian-spicy-dish-from-bousaada-region-called-zviti/\n",
            "Error fetching or parsing https://www.thefooddictator.com/hirshon-algerian-berkoukes-soup-%D8%A8%D8%B1%D9%83%D9%88%D9%83%D8%B3/: 403 Client Error: Forbidden for url: https://www.thefooddictator.com/hirshon-algerian-berkoukes-soup-%D8%A8%D8%B1%D9%83%D9%88%D9%83%D8%B3/\n",
            "Error fetching or parsing https://www.myexcellentdegustations.com/%F0%9F%87%A9%F0%9F%87%BF-algerian-homemade-rechta-noodles/: 406 Client Error: Not Acceptable for url: https://www.myexcellentdegustations.com/%F0%9F%87%A9%F0%9F%87%BF-algerian-homemade-rechta-noodles/\n",
            "Error fetching or parsing https://www.notesfromamessykitchen.com/recipe/algerian-makroud/: 406 Client Error: Not Acceptable for url: https://www.notesfromamessykitchen.com/recipe/algerian-makroud/\n",
            "Error fetching or parsing https://tastymediterranean.com/recipe/how-to-prepare-authentic-algerian-tamina/: 403 Client Error: Forbidden for url: https://tastymediterranean.com/recipe/how-to-prepare-authentic-algerian-tamina/\n",
            "Scraping complete! Data saved to algerian_recipes.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# URL of the target page\n",
        "url = 'https://www.chefspencil.com/top-25-most-popular-foods-in-algeria/'\n",
        "\n",
        "# Send HTTP GET request to the page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the page content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # List to store recipe data\n",
        "    recipes = []\n",
        "\n",
        "    # Find all <h2> tags containing the dish names\n",
        "    dish_elements = soup.find_all('h2', class_='wp-block-heading')\n",
        "\n",
        "    # Iterate through each dish\n",
        "    for dish_element in dish_elements:\n",
        "        dish_name = dish_element.get_text(strip=True)\n",
        "\n",
        "        # Find the link to the recipe associated with the dish\n",
        "        recipe_link_element = dish_element.find_next('a', class_='wp-block-button__link')\n",
        "        if recipe_link_element:\n",
        "            recipe_link = recipe_link_element['href']\n",
        "\n",
        "            try:\n",
        "                # Send a request to the recipe page\n",
        "                recipe_response = requests.get(recipe_link)\n",
        "                recipe_response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "                # Parse the recipe page\n",
        "                recipe_soup = BeautifulSoup(recipe_response.text, 'html.parser')\n",
        "\n",
        "                # Find the recipe name on the recipe page\n",
        "                recipe_name_element = recipe_soup.find('h2', class_='wprm-recipe-name')\n",
        "                recipe_name = recipe_name_element.get_text(strip=True) if recipe_name_element else \"Recipe Name Not Found\"\n",
        "\n",
        "                # Find the ingredient list on the recipe page\n",
        "                ingredients_container = recipe_soup.find('div', class_='wprm-recipe-ingredients-container')\n",
        "                if ingredients_container:\n",
        "                    # Extract ingredients grouped by section\n",
        "                    ingredients = []\n",
        "                    for group in ingredients_container.find_all('div', class_='wprm-recipe-ingredient-group'):\n",
        "                        group_name = group.find('h4', class_='wprm-recipe-group-name')\n",
        "                        group_name = group_name.get_text(strip=True) if group_name else \"General\"\n",
        "                        group_ingredients = [li.get_text(strip=True) for li in group.find_all('li', class_='wprm-recipe-ingredient')]\n",
        "                        ingredients.append({group_name: group_ingredients})\n",
        "\n",
        "                    recipes.append({\n",
        "                        'Dish Name': dish_name,\n",
        "                        'Recipe Link': recipe_link,\n",
        "                        'Recipe Name': recipe_name,\n",
        "                        'Ingredients': ingredients\n",
        "                    })\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Error fetching or parsing {recipe_link}: {e}\")\n",
        "\n",
        "    # Write the scraped data to a CSV file\n",
        "    with open('recipes.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['Dish Name', 'Recipe Link', 'Recipe Name', 'Ingredients']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for recipe in recipes:\n",
        "            writer.writerow({\n",
        "                'Dish Name': recipe['Dish Name'],\n",
        "                'Recipe Link': recipe['Recipe Link'],\n",
        "                'Recipe Name': recipe['Recipe Name'],\n",
        "                'Ingredients': recipe['Ingredients']\n",
        "            })\n",
        "\n",
        "    print(\"Scraping complete! Data saved to recipes.csv\")\n",
        "else:\n",
        "    print(\"Failed to retrieve the main page.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C247JHxgJ_4D",
        "outputId": "e25bb0d6-e4ed-4e97-bdf1-83fdaf0c40f4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching or parsing https://www.myexcellentdegustations.com/algerian-thin-flatbread-with-meat-sauce-chakhchoukha/: 406 Client Error: Not Acceptable for url: https://www.myexcellentdegustations.com/algerian-thin-flatbread-with-meat-sauce-chakhchoukha/\n",
            "Error fetching or parsing https://www.myexcellentdegustations.com/%F0%9F%87%A9%F0%9F%87%BF-algerian-spicy-dish-from-bousaada-region-called-zviti/: 406 Client Error: Not Acceptable for url: https://www.myexcellentdegustations.com/%F0%9F%87%A9%F0%9F%87%BF-algerian-spicy-dish-from-bousaada-region-called-zviti/\n",
            "Error fetching or parsing https://www.thefooddictator.com/hirshon-algerian-berkoukes-soup-%D8%A8%D8%B1%D9%83%D9%88%D9%83%D8%B3/: 403 Client Error: Forbidden for url: https://www.thefooddictator.com/hirshon-algerian-berkoukes-soup-%D8%A8%D8%B1%D9%83%D9%88%D9%83%D8%B3/\n",
            "Error fetching or parsing https://www.thefooddictator.com/hirshon-algerian-berkoukes-soup-%D8%A8%D8%B1%D9%83%D9%88%D9%83%D8%B3/: 403 Client Error: Forbidden for url: https://www.thefooddictator.com/hirshon-algerian-berkoukes-soup-%D8%A8%D8%B1%D9%83%D9%88%D9%83%D8%B3/\n",
            "Error fetching or parsing https://www.myexcellentdegustations.com/%F0%9F%87%A9%F0%9F%87%BF-algerian-homemade-rechta-noodles/: 406 Client Error: Not Acceptable for url: https://www.myexcellentdegustations.com/%F0%9F%87%A9%F0%9F%87%BF-algerian-homemade-rechta-noodles/\n",
            "Error fetching or parsing https://www.notesfromamessykitchen.com/recipe/algerian-makroud/: 406 Client Error: Not Acceptable for url: https://www.notesfromamessykitchen.com/recipe/algerian-makroud/\n",
            "Error fetching or parsing https://tastymediterranean.com/recipe/how-to-prepare-authentic-algerian-tamina/: 403 Client Error: Forbidden for url: https://tastymediterranean.com/recipe/how-to-prepare-authentic-algerian-tamina/\n",
            "Scraping complete! Data saved to recipes.csv\n"
          ]
        }
      ]
    }
  ]
}